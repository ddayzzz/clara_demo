{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据划分\n",
    "每个客户端拥有若干的机构的联合的数据(因为GPU资源不够), train和validation来源相同, 构建的联合模型则是在BRATS2018和BRATS2019的差集上验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义相关的参数\n",
    "PREFIX = 'clara_seg_ct_brats_fl'\n",
    "BRATS_PREFIX = '/home/liuyuan/shu_codes/datasets/brats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HGG: 210, LGG: 75\n",
      "HGG: 259, LGG: 76\n",
      "                       id hgg_or_lgg institution       ins_pid\n",
      "0    Brats18_TCIA03_257_1        hgg      TCIA03  TCIA03_257_1\n",
      "1    Brats18_TCIA03_296_1        hgg      TCIA03  TCIA03_296_1\n",
      "2     Brats18_CBICA_ANZ_1        hgg       CBICA   CBICA_ANZ_1\n",
      "3    Brats18_TCIA06_165_1        hgg      TCIA06  TCIA06_165_1\n",
      "4    Brats18_TCIA01_412_1        hgg      TCIA01  TCIA01_412_1\n",
      "..                    ...        ...         ...           ...\n",
      "280  Brats18_TCIA09_462_1        lgg      TCIA09  TCIA09_462_1\n",
      "281  Brats18_TCIA12_101_1        lgg      TCIA12  TCIA12_101_1\n",
      "282  Brats18_TCIA13_653_1        lgg      TCIA13  TCIA13_653_1\n",
      "283  Brats18_TCIA10_299_1        lgg      TCIA10  TCIA10_299_1\n",
      "284  Brats18_TCIA09_451_1        lgg      TCIA09  TCIA09_451_1\n",
      "\n",
      "[285 rows x 4 columns]\n",
      "                       id hgg_or_lgg institution       ins_pid\n",
      "0     BraTS19_CBICA_BGX_1        hgg       CBICA   CBICA_BGX_1\n",
      "1     BraTS19_CBICA_ALN_1        hgg       CBICA   CBICA_ALN_1\n",
      "2     BraTS19_CBICA_AXL_1        hgg       CBICA   CBICA_AXL_1\n",
      "3     BraTS19_CBICA_AYG_1        hgg       CBICA   CBICA_AYG_1\n",
      "4     BraTS19_CBICA_ASH_1        hgg       CBICA   CBICA_ASH_1\n",
      "..                    ...        ...         ...           ...\n",
      "330      BraTS19_2013_8_1        lgg        2013      2013_8_1\n",
      "331   BraTS19_TMC_09043_1        lgg         TMC   TMC_09043_1\n",
      "332  BraTS19_TCIA10_628_1        lgg      TCIA10  TCIA10_628_1\n",
      "333  BraTS19_TCIA10_639_1        lgg      TCIA10  TCIA10_639_1\n",
      "334  BraTS19_TCIA13_624_1        lgg      TCIA13  TCIA13_624_1\n",
      "\n",
      "[335 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def get_data_info(data_prefix, channels, ):\n",
    "    data_info = pd.DataFrame(columns=['id', 'hgg_or_lgg', 'institution', 'ins_pid'])\n",
    "    # 遍历对应的目录\n",
    "    hgg_dirs = glob.glob(os.path.join(data_prefix, 'HGG', '**'))\n",
    "    lgg_dirs = glob.glob(os.path.join(data_prefix, 'LGG', '**'))\n",
    "    print(f'HGG: {len(hgg_dirs)}, LGG: {len(lgg_dirs)}')\n",
    "    for gg_type, gg in (('hgg', hgg_dirs), ('lgg', lgg_dirs)):\n",
    "        names = [os.path.basename(x) for x in gg]\n",
    "        for name in names:\n",
    "            items = name.split('_')\n",
    "            data_info = data_info.append({'id': name, 'hgg_or_lgg': gg_type, 'institution': items[1], 'ins_pid': '_'.join(items[1:])}, ignore_index=True)\n",
    "    return data_info\n",
    "        \n",
    "\n",
    "channels = ['t1ce', 't1', 't2', 'flair']\n",
    "channel_suffix = ['_t1ce.nii.gz', '_t1.nii.gz', '_t2.nii.gz', '_flair.nii.gz']\n",
    "mask_suffix = '_seg.nii.gz'\n",
    "all_2018_info = get_data_info(BRATS_PREFIX + '/MICCAI_BraTS_2018_Data_Training', channels)\n",
    "all_2019_info = get_data_info(BRATS_PREFIX + '/MICCAI_BraTS_2019_Data_Training', channels)\n",
    "print(all_2018_info)\n",
    "print(all_2019_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      id hgg_or_lgg institution      ins_pid\n",
      "0    BraTS19_CBICA_BGX_1        hgg       CBICA  CBICA_BGX_1\n",
      "3    BraTS19_CBICA_AYG_1        hgg       CBICA  CBICA_AYG_1\n",
      "13   BraTS19_CBICA_BCF_1        hgg       CBICA  CBICA_BCF_1\n",
      "15   BraTS19_CBICA_AVB_1        hgg       CBICA  CBICA_AVB_1\n",
      "16   BraTS19_CBICA_BGW_1        hgg       CBICA  CBICA_BGW_1\n",
      "17   BraTS19_CBICA_BJY_1        hgg       CBICA  CBICA_BJY_1\n",
      "18   BraTS19_CBICA_AOC_1        hgg       CBICA  CBICA_AOC_1\n",
      "23   BraTS19_CBICA_BGG_1        hgg       CBICA  CBICA_BGG_1\n",
      "29   BraTS19_CBICA_BGT_1        hgg       CBICA  CBICA_BGT_1\n",
      "32   BraTS19_TMC_11964_1        hgg         TMC  TMC_11964_1\n",
      "36   BraTS19_TMC_12866_1        hgg         TMC  TMC_12866_1\n",
      "38   BraTS19_TMC_21360_1        hgg         TMC  TMC_21360_1\n",
      "48   BraTS19_CBICA_BGE_1        hgg       CBICA  CBICA_BGE_1\n",
      "54   BraTS19_CBICA_ATN_1        hgg       CBICA  CBICA_ATN_1\n",
      "56   BraTS19_TMC_27374_1        hgg         TMC  TMC_27374_1\n",
      "59   BraTS19_CBICA_BHZ_1        hgg       CBICA  CBICA_BHZ_1\n",
      "65   BraTS19_CBICA_BNR_1        hgg       CBICA  CBICA_BNR_1\n",
      "69   BraTS19_TMC_15477_1        hgg         TMC  TMC_15477_1\n",
      "71   BraTS19_CBICA_BLJ_1        hgg       CBICA  CBICA_BLJ_1\n",
      "74   BraTS19_CBICA_AOS_1        hgg       CBICA  CBICA_AOS_1\n",
      "75   BraTS19_CBICA_AYC_1        hgg       CBICA  CBICA_AYC_1\n",
      "76   BraTS19_CBICA_BGN_1        hgg       CBICA  CBICA_BGN_1\n",
      "91   BraTS19_CBICA_APK_1        hgg       CBICA  CBICA_APK_1\n",
      "93   BraTS19_CBICA_BGO_1        hgg       CBICA  CBICA_BGO_1\n",
      "94   BraTS19_TMC_06290_1        hgg         TMC  TMC_06290_1\n",
      "95   BraTS19_CBICA_AVF_1        hgg       CBICA  CBICA_AVF_1\n",
      "106  BraTS19_CBICA_BIC_1        hgg       CBICA  CBICA_BIC_1\n",
      "109  BraTS19_TMC_30014_1        hgg         TMC  TMC_30014_1\n",
      "111  BraTS19_CBICA_BKV_1        hgg       CBICA  CBICA_BKV_1\n",
      "116  BraTS19_CBICA_ASF_1        hgg       CBICA  CBICA_ASF_1\n",
      "121  BraTS19_CBICA_AUX_1        hgg       CBICA  CBICA_AUX_1\n",
      "122  BraTS19_CBICA_ANV_1        hgg       CBICA  CBICA_ANV_1\n",
      "131  BraTS19_CBICA_AWV_1        hgg       CBICA  CBICA_AWV_1\n",
      "133  BraTS19_CBICA_BDK_1        hgg       CBICA  CBICA_BDK_1\n",
      "149  BraTS19_CBICA_AVT_1        hgg       CBICA  CBICA_AVT_1\n",
      "154  BraTS19_CBICA_BAN_1        hgg       CBICA  CBICA_BAN_1\n",
      "167  BraTS19_TMC_06643_1        hgg         TMC  TMC_06643_1\n",
      "168  BraTS19_CBICA_ASR_1        hgg       CBICA  CBICA_ASR_1\n",
      "178  BraTS19_CBICA_BAX_1        hgg       CBICA  CBICA_BAX_1\n",
      "191  BraTS19_CBICA_BBG_1        hgg       CBICA  CBICA_BBG_1\n",
      "194  BraTS19_CBICA_BEM_1        hgg       CBICA  CBICA_BEM_1\n",
      "203  BraTS19_CBICA_AUA_1        hgg       CBICA  CBICA_AUA_1\n",
      "204  BraTS19_CBICA_BGR_1        hgg       CBICA  CBICA_BGR_1\n",
      "211  BraTS19_CBICA_AWX_1        hgg       CBICA  CBICA_AWX_1\n",
      "218  BraTS19_CBICA_BHV_1        hgg       CBICA  CBICA_BHV_1\n",
      "225  BraTS19_CBICA_BHQ_1        hgg       CBICA  CBICA_BHQ_1\n",
      "230  BraTS19_CBICA_BAP_1        hgg       CBICA  CBICA_BAP_1\n",
      "234  BraTS19_CBICA_AUW_1        hgg       CBICA  CBICA_AUW_1\n",
      "253  BraTS19_CBICA_BCL_1        hgg       CBICA  CBICA_BCL_1\n",
      "331  BraTS19_TMC_09043_1        lgg         TMC  TMC_09043_1\n"
     ]
    }
   ],
   "source": [
    "# 以 brats2018 作为训练数据, 2019作为测试数据, 需要计算二者的差值\n",
    "def get_different(df1, df2):\n",
    "    # apply 第二参数, 1为column, 0 为 index. https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html\n",
    "    c1 = df1[['ins_pid']].apply(tuple,1)\n",
    "    c2 = df2[['ins_pid']].apply(tuple,1)\n",
    "    return df2[~c2.isin(c1)]\n",
    "\n",
    "brats_2019_part = get_different(all_2018_info, all_2019_info)\n",
    "print(brats_2019_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "institution:  {'TCIA04', 'TCIA02', 'TCIA06', 'TCIA05', 'TCIA12', 'TCIA01', 'TCIA09', 'TCIA10', 'CBICA', 'TCIA03', 'TCIA08', 'TCIA13', '2013'}\n",
      "\t TCIA04 : 8\n",
      "\t TCIA02 : 34\n",
      "\t TCIA06 : 8\n",
      "\t TCIA05 : 4\n",
      "\t TCIA12 : 6\n",
      "\t TCIA01 : 22\n",
      "\t TCIA09 : 11\n",
      "\t TCIA10 : 35\n",
      "\t CBICA : 88\n",
      "\t TCIA03 : 12\n",
      "\t TCIA08 : 14\n",
      "\t TCIA13 : 13\n",
      "\t 2013 : 30\n",
      "institution:  {'CBICA', 'TMC'}\n",
      "\t CBICA : 41\n",
      "\t TMC : 9\n"
     ]
    }
   ],
   "source": [
    "# 输出一些统计信息\n",
    "def print_insitutions_info(df):\n",
    "    ds = dict()\n",
    "    inst = set(df['institution'].to_list())\n",
    "    print('institution: ', inst)\n",
    "    for ins in inst:\n",
    "        ds[ins] = len(df[df['institution'] == ins])\n",
    "    for k, v in ds.items():\n",
    "        print('\\t', k, ':', v)\n",
    "\n",
    "print_insitutions_info(all_2018_info)\n",
    "print_insitutions_info(brats_2019_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client  0 ,num_train:  74 , num_test:  14 , write to  clara_seg_ct_brats_fl/config/fl_dataset_0.json\n",
      "Client  1 ,num_train:  50 , num_test:  9 , write to  clara_seg_ct_brats_fl/config/fl_dataset_1.json\n",
      "Client  2 ,num_train:  25 , num_test:  5 , write to  clara_seg_ct_brats_fl/config/fl_dataset_2.json\n",
      "Client  3 ,num_train:  37 , num_test:  7 , write to  clara_seg_ct_brats_fl/config/fl_dataset_3.json\n",
      "Client  4 ,num_train:  17 , num_test:  4 , write to  clara_seg_ct_brats_fl/config/fl_dataset_4.json\n",
      "Client  5 ,num_train:  36 , num_test:  7 , write to  clara_seg_ct_brats_fl/config/fl_dataset_5.json\n"
     ]
    }
   ],
   "source": [
    "# 合并一些文件, 因为资源确实有限, 目前试一下只使用若干的机构, 这些机构同时含有测试(validation)和训练\n",
    "import json\n",
    "import numpy as np\n",
    "np.random.seed(100)\n",
    "\n",
    "\n",
    "def write_to_clara_info(client_id, df, sub_name, train_validation_rate=0.85):\n",
    "    path = os.path.join(PREFIX, 'config', 'fl_dataset_{}.json'.format(client_id))\n",
    "    images_masks = []\n",
    "    for gg_type, pid in zip(df['hgg_or_lgg'], df['id']):\n",
    "        channel_filepath = [os.path.join(sub_name, gg_type.upper(), pid, pid + channel_suffix[i]) for i, c in enumerate(channels)]\n",
    "        mask_filepath = os.path.join(sub_name, gg_type.upper(), pid, pid + mask_suffix)\n",
    "        images_masks.append({'image': channel_filepath, 'label': mask_filepath})\n",
    "    # 随机排序\n",
    "    np.random.shuffle(images_masks)\n",
    "    # 拆分数据\n",
    "    n_trains = int(len(images_masks) * train_validation_rate)\n",
    "    n_tests = len(images_masks) - n_trains\n",
    "    print('Client ', client_id, ',num_train: ', n_trains, ', num_test: ', n_tests, ', write to ', path)\n",
    "    # \n",
    "    target = dict(training=images_masks[:n_trains], validation=images_masks[n_trains:], description='BRATS')\n",
    "    with open(path, 'w') as fp:\n",
    "        json.dump(target, fp)\n",
    "\n",
    "        \n",
    "def merge_inst(inst1, inst2):\n",
    "    df = pd.concat([inst1, inst2])\n",
    "    return df\n",
    "\n",
    "# 使用三张卡\n",
    "# inst_merged = [\n",
    "#         ['CBICA'], ['TCIA13', 'TCIA02', '2013', 'TCIA01', 'TCIA08'],\n",
    "#         ['TCIA09', 'TCIA12', 'TCIA10', 'TCIA04', 'TCIA06', 'TCIA03', 'TCIA05']\n",
    "#     ]\n",
    "# 使用6张卡\n",
    "inst_merged = [\n",
    "        ['CBICA'], ['TCIA13', 'TCIA02', 'TCIA03'], ['2013'], ['TCIA01', 'TCIA08', 'TCIA06'],\n",
    "        ['TCIA09', 'TCIA12', 'TCIA05'], ['TCIA10', 'TCIA04']\n",
    "    ]\n",
    "ms = []\n",
    "for i, inss in enumerate(inst_merged):\n",
    "    tag = all_2018_info[all_2018_info['institution'] == inss[0]]\n",
    "    for j in range(1, len(inss)):\n",
    "        tag = merge_inst(tag, all_2018_info[all_2018_info['institution'] == inss[j]])\n",
    "    ms.append(tag)\n",
    "for i, item in enumerate(ms):\n",
    "    write_to_clara_info(i, item, 'MICCAI_BraTS_2018_Data_Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1, 写入 environment.json 格式的数据, 写入对应的 test! 似乎是以 . 开头的\n",
    "target = dict()\n",
    "env_json = os.path.join(BRATS_PREFIX, 'datalist.json')\n",
    "sub_name = 'MICCAI_BraTS_2018_Data_Training'\n",
    "# training 部分\n",
    "images_masks = []\n",
    "for gg_type, pid in zip(all_2018_info['hgg_or_lgg'], all_2018_info['id']):\n",
    "    channel_filepath = [os.path.join('.', sub_name, gg_type.upper(), pid, pid + channel_suffix[i]) for i, c in enumerate(channels)]\n",
    "    mask_filepath = os.path.join('.', sub_name, gg_type.upper(), pid, pid + mask_suffix)\n",
    "    images_masks.append({'image': channel_filepath, 'label': mask_filepath})\n",
    "target['training'] = images_masks\n",
    "# testing 部分\n",
    "images_masks = []\n",
    "sub_name = 'MICCAI_BraTS_2019_Data_Training'\n",
    "for gg_type, pid in zip(brats_2019_part['hgg_or_lgg'], brats_2019_part['id']):\n",
    "    channel_filepath = [os.path.join('.', sub_name, gg_type.upper(), pid, pid + channel_suffix[i]) for i, c in enumerate(channels)]\n",
    "    mask_filepath = os.path.join('.', sub_name, gg_type.upper(), pid, pid + mask_suffix)\n",
    "    images_masks.append({'image': channel_filepath, 'label': mask_filepath})\n",
    "target['test'] = images_masks\n",
    "# 吸入\n",
    "with open(env_json, 'w') as fp:\n",
    "    json.dump(target, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2, 写入json文件到程序的目录\n",
    "target = dict()\n",
    "env_json = 'clara_seg_ct_brats_fl/config/2018train_2019test.json'\n",
    "sub_name = 'MICCAI_BraTS_2018_Data_Training'\n",
    "# training 部分\n",
    "images_masks = []\n",
    "for gg_type, pid in zip(all_2018_info['hgg_or_lgg'], all_2018_info['id']):\n",
    "    channel_filepath = [os.path.join(sub_name, gg_type.upper(), pid, pid + channel_suffix[i]) for i, c in enumerate(channels)]\n",
    "    mask_filepath = os.path.join(sub_name, gg_type.upper(), pid, pid + mask_suffix)\n",
    "    images_masks.append({'image': channel_filepath, 'label': mask_filepath})\n",
    "target['training'] = images_masks\n",
    "# testing 部分\n",
    "images_masks = []\n",
    "sub_name = 'MICCAI_BraTS_2019_Data_Training'\n",
    "for gg_type, pid in zip(brats_2019_part['hgg_or_lgg'], brats_2019_part['id']):\n",
    "    channel_filepath = [os.path.join(sub_name, gg_type.upper(), pid, pid + channel_suffix[i]) for i, c in enumerate(channels)]\n",
    "    mask_filepath = os.path.join(sub_name, gg_type.upper(), pid, pid + mask_suffix)\n",
    "    images_masks.append({'image': channel_filepath, 'label': mask_filepath})\n",
    "target['test'] = images_masks\n",
    "# 吸入\n",
    "with open(env_json, 'w') as fp:\n",
    "    json.dump(target, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里是写入普通的集中式学习方式\n",
    "config_filepath = 'clara_seg_ct_brats/config/2018train_2019test.json'\n",
    "target = dict()\n",
    "sub_name = 'MICCAI_BraTS_2018_Data_Training'\n",
    "# training 部分\n",
    "images_masks = []\n",
    "for gg_type, pid in zip(all_2018_info['hgg_or_lgg'], all_2018_info['id']):\n",
    "    channel_filepath = [os.path.join(sub_name, gg_type.upper(), pid, pid + channel_suffix[i]) for i, c in enumerate(channels)]\n",
    "    mask_filepath = os.path.join(sub_name, gg_type.upper(), pid, pid + mask_suffix)\n",
    "    images_masks.append({'image': channel_filepath, 'label': mask_filepath})\n",
    "target['training'] = images_masks\n",
    "# testing 部分\n",
    "images_masks = []\n",
    "sub_name = 'MICCAI_BraTS_2019_Data_Training'\n",
    "for gg_type, pid in zip(brats_2019_part['hgg_or_lgg'], brats_2019_part['id']):\n",
    "    channel_filepath = [os.path.join(sub_name, gg_type.upper(), pid, pid + channel_suffix[i]) for i, c in enumerate(channels)]\n",
    "    mask_filepath = os.path.join(sub_name, gg_type.upper(), pid, pid + mask_suffix)\n",
    "    images_masks.append({'image': channel_filepath, 'label': mask_filepath})\n",
    "target['validation'] = images_masks\n",
    "target['test'] = []\n",
    "# 吸入\n",
    "with open(config_filepath, 'w') as fp:\n",
    "    json.dump(target, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
